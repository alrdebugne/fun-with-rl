{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa58bc0-6ebd-46d3-abc9-f8c49c85c086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare learning rates of VPG and VPG-GAE(gamma, lambda) with different values for lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2d08f4-922c-4108-ad05-32c5f67305cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "ROOT = Path(\"/Users/debugneantoine/Documents/personal/dqn-super-mario-bros/\")\n",
    "os.chdir(ROOT)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "params = {\n",
    "    \"ytick.color\" : \"w\",\n",
    "    \"xtick.color\" : \"w\",\n",
    "    \"axes.labelcolor\" : \"w\",\n",
    "    \"axes.edgecolor\" : \"w\",\n",
    "    \"axes.titlecolor\": \"w\"\n",
    "}\n",
    "plt.rcParams.update(params)\n",
    "import torch\n",
    "import gym\n",
    "import gym_super_mario_bros\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT\n",
    "\n",
    "from agent import VPGAgent, VPGGAEAgent, CategoricalMLP, CategoricalCNN\n",
    "from wrappers import make_env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86029e6-b8f3-47e0-9603-196eb3e4973f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create environment\n",
    "env = gym.make(\"LunarLander-v2\")\n",
    "observation_space = env.observation_space.shape[0]\n",
    "action_space = env.action_space.n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771de221-a400-47e8-b965-7e1201909b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare all combinations we want to test\n",
    "# 1a. VPG undiscounted\n",
    "# 1b. VPG w/ gamma = 0.99\n",
    "# 2a. VPG-GAE: gamma = 0.99, lambda = 0\n",
    "# 2b. VPG-GAE: gamma = 0.99, lambda = 0.9\n",
    "# 2c. VPG-GAE: gamma = 0.99, lambda = 0.95\n",
    "# 2d. VPG-GAE: gamma = 0.99, lambda = 0.97\n",
    "# 2e. VPG-GAE: gamma = 0.99, lambda = 0.99\n",
    "\n",
    "agent_classes = [VPGAgent] * 2 + [VPGGAEAgent] * 5\n",
    "gammas = [1.] + [0.99] * 6\n",
    "lambdas = [None, None, 0, 0.9, 0.95, 0.97, 0.99]\n",
    "\n",
    "def get_base_args_vpg_gae(observation_space, action_space) -> dict:\n",
    "    return {\n",
    "        # Environment params\n",
    "        \"state_space\": observation_space,\n",
    "        \"action_space\": action_space,\n",
    "        # Policy net params\n",
    "        \"lr\": 0.02,\n",
    "        \"policy_net\": CategoricalMLP,\n",
    "        \"policy_net_kwargs\": {\"input_shape\": observation_space, \"n_actions\": action_space, \"hidden_sizes\": [32]},\n",
    "        # Value func net params\n",
    "        \"value_func_net\": CategoricalMLP,\n",
    "        \"value_func_net_kwargs\": {\"input_shape\": observation_space, \"n_actions\": 1, \"hidden_sizes\": [32]},\n",
    "        \"value_func_lr\": 0.02,\n",
    "    }\n",
    "\n",
    "def get_base_args_vpg(observation_space, action_space) -> dict:\n",
    "    return {\n",
    "        # Environment params\n",
    "        \"state_space\": observation_space,\n",
    "        \"action_space\": action_space,\n",
    "        # Policy net params\n",
    "        \"lr\": 0.02,\n",
    "        \"policy_net\": CategoricalMLP,\n",
    "        \"policy_net_kwargs\": {\"input_shape\": observation_space, \"n_actions\": action_space, \"hidden_sizes\": [32]},\n",
    "    }\n",
    "    \n",
    "args_funcs = [get_base_args_vpg] * 2 + [get_base_args_vpg_gae] * 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9425af-8f08-4236-8ea5-db14f34a4ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_returns = []\n",
    "\n",
    "for i, (agent_class, get_args, gamma, _lambda) in enumerate(zip(agent_classes, args_funcs, gammas, lambdas)):\n",
    "\n",
    "    print(f\"Run {i}: (gamma, lambda) = ({gamma}, {_lambda})\")\n",
    "    \n",
    "    # Reset environment\n",
    "    env.seed(0)\n",
    "    env.reset()\n",
    "\n",
    "    # Instantiate agent\n",
    "    _args = get_args(observation_space, action_space)\n",
    "    _args[\"gamma\"] = gamma\n",
    "    if _lambda is not None:\n",
    "        _args[\"value_func_lambda\"] = _lambda\n",
    "    _agent = agent_class(**_args)\n",
    "\n",
    "    # Train agent on 200 epochs\n",
    "    _infos = _agent.run(\n",
    "        env, num_epochs=200, steps_per_epoch=500, save_after_epochs=9999, print_progress_after=50,\n",
    "    )\n",
    "    # Save avg. return per epoch\n",
    "    loss_col = \"loss_policy\" if \"loss_policy\" in _infos.columns else \"loss\"\n",
    "    _res = _infos[[\"epoch\", \"average_return\", loss_col]].drop_duplicates()\\\n",
    "        .rename(columns={loss_col: \"loss_policy\"})\n",
    "    _res[\"exp\"] = i\n",
    "    avg_returns.append(_res)\n",
    "\n",
    "avg_returns = pd.concat(avg_returns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bc6a2d-b479-43cc-9066-b33009b19978",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(figsize=(14, 5), nrows=1, ncols=2)\n",
    "legends= []\n",
    "\n",
    "for i, (gamma, _lambda) in enumerate(zip(gammas, lambdas)):\n",
    "    _class = \"VPG\" if i < 2 else \"VPG-GAE\"\n",
    "    legends.append(f\"{_class}, (gamma, lambda) = ({gamma}, {_lambda})\")    \n",
    "    \n",
    "    _returns = avg_returns.loc[avg_returns[\"exp\"] == i]\n",
    "    axes[0].plot(_returns[\"epoch\"], _returns[\"average_return\"])\n",
    "    axes[1].plot(_returns[\"epoch\"], _returns[\"loss_policy\"])\n",
    "\n",
    "axes[0].set_title(\"Avg. returns per episode\")\n",
    "axes[0].grid(axis=\"y\", color=\"0.9\")\n",
    "axes[1].set_title(\"Policy loss per episode\")\n",
    "axes[1].grid(axis=\"y\", color=\"0.9\")\n",
    "axes[1].legend(legends)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35093372-59af-473d-ba3f-be59c2f40458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cef2f1-6a9d-4304-b389-aa520f574070",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
